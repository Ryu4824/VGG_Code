{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 레이어 구현"
      ],
      "metadata": {
        "id": "xAf5gwksgOMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "4Ifm1WNt04ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e4a264-2fe8-4a94-8597-b6d55df91783"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "yAf2orxH033G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PKsQs3E306gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a4301a-6d9d-4440-8340-b0935583e0f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "cAGvdcau08Rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cb774a-35ab-4db5-da01-20ff75ea03af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, pool=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        ]\n",
        "        if pool:\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ],
      "metadata": {
        "id": "IW-bSbY_VPe-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tJ5W-Z5gvM_8"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, block, num_classes=1000):\n",
        "        super(VGG, self).__init__()\n",
        "\n",
        "        if block == 'vgg16':\n",
        "          num = 3\n",
        "        elif block == 'vgg19':\n",
        "          num = 4\n",
        "\n",
        "        self.conv1 = ConvBlock(3, 64)\n",
        "        self.conv2 = ConvBlock(64, 64, pool=True)\n",
        "\n",
        "        self.conv3 = ConvBlock(64, 128)\n",
        "        self.conv4 = ConvBlock(128, 128, pool=True)\n",
        "\n",
        "        self.conv5 = ConvBlock(128, 256)\n",
        "        self.conv6 = self._make_layers(256, num)\n",
        "\n",
        "        self.conv7 = ConvBlock(256, 512)\n",
        "        self.conv8 = self._make_layers(512, num)\n",
        "\n",
        "        self.conv9 = ConvBlock(512, 512)\n",
        "        self.conv10 = self._make_layers(512, num)\n",
        "\n",
        "\n",
        "        # Adaptive Average Pooling Layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def _make_layers(self, in_ch, num):\n",
        "        layers = []\n",
        "        for _ in range(num - 2):\n",
        "            layers.append(ConvBlock(in_ch, in_ch))\n",
        "        layers.append(ConvBlock(in_ch, in_ch,pool=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # 정규 분포에서 가중치 초기화\n",
        "                nn.init.normal_(m.weight, mean=0, std=1e-2)\n",
        "                # 편향을 0으로 초기화\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.conv10(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG('vgg16',num_classes=10).to(device)\n",
        "features = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "summary(model, input_data=features, col_names=(\"input_size\", \"output_size\", \"num_params\"), device=device.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfPAarxLa13o",
        "outputId": "45ef9e8d-72fd-474f-c319-b04b48395c2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "VGG                                      [1, 3, 224, 224]          [1, 10]                   --\n",
              "├─ConvBlock: 1-1                         [1, 3, 224, 224]          [1, 64, 224, 224]         --\n",
              "│    └─Sequential: 2-1                   [1, 3, 224, 224]          [1, 64, 224, 224]         --\n",
              "│    │    └─Conv2d: 3-1                  [1, 3, 224, 224]          [1, 64, 224, 224]         1,792\n",
              "│    │    └─BatchNorm2d: 3-2             [1, 64, 224, 224]         [1, 64, 224, 224]         128\n",
              "│    │    └─ReLU: 3-3                    [1, 64, 224, 224]         [1, 64, 224, 224]         --\n",
              "├─ConvBlock: 1-2                         [1, 64, 224, 224]         [1, 64, 112, 112]         --\n",
              "│    └─Sequential: 2-2                   [1, 64, 224, 224]         [1, 64, 112, 112]         --\n",
              "│    │    └─Conv2d: 3-4                  [1, 64, 224, 224]         [1, 64, 224, 224]         36,928\n",
              "│    │    └─BatchNorm2d: 3-5             [1, 64, 224, 224]         [1, 64, 224, 224]         128\n",
              "│    │    └─ReLU: 3-6                    [1, 64, 224, 224]         [1, 64, 224, 224]         --\n",
              "│    │    └─MaxPool2d: 3-7               [1, 64, 224, 224]         [1, 64, 112, 112]         --\n",
              "├─ConvBlock: 1-3                         [1, 64, 112, 112]         [1, 128, 112, 112]        --\n",
              "│    └─Sequential: 2-3                   [1, 64, 112, 112]         [1, 128, 112, 112]        --\n",
              "│    │    └─Conv2d: 3-8                  [1, 64, 112, 112]         [1, 128, 112, 112]        73,856\n",
              "│    │    └─BatchNorm2d: 3-9             [1, 128, 112, 112]        [1, 128, 112, 112]        256\n",
              "│    │    └─ReLU: 3-10                   [1, 128, 112, 112]        [1, 128, 112, 112]        --\n",
              "├─ConvBlock: 1-4                         [1, 128, 112, 112]        [1, 128, 56, 56]          --\n",
              "│    └─Sequential: 2-4                   [1, 128, 112, 112]        [1, 128, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-11                 [1, 128, 112, 112]        [1, 128, 112, 112]        147,584\n",
              "│    │    └─BatchNorm2d: 3-12            [1, 128, 112, 112]        [1, 128, 112, 112]        256\n",
              "│    │    └─ReLU: 3-13                   [1, 128, 112, 112]        [1, 128, 112, 112]        --\n",
              "│    │    └─MaxPool2d: 3-14              [1, 128, 112, 112]        [1, 128, 56, 56]          --\n",
              "├─ConvBlock: 1-5                         [1, 128, 56, 56]          [1, 256, 56, 56]          --\n",
              "│    └─Sequential: 2-5                   [1, 128, 56, 56]          [1, 256, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-15                 [1, 128, 56, 56]          [1, 256, 56, 56]          295,168\n",
              "│    │    └─BatchNorm2d: 3-16            [1, 256, 56, 56]          [1, 256, 56, 56]          512\n",
              "│    │    └─ReLU: 3-17                   [1, 256, 56, 56]          [1, 256, 56, 56]          --\n",
              "├─Sequential: 1-6                        [1, 256, 56, 56]          [1, 256, 28, 28]          --\n",
              "│    └─ConvBlock: 2-6                    [1, 256, 56, 56]          [1, 256, 56, 56]          --\n",
              "│    │    └─Sequential: 3-18             [1, 256, 56, 56]          [1, 256, 56, 56]          590,592\n",
              "│    └─ConvBlock: 2-7                    [1, 256, 56, 56]          [1, 256, 28, 28]          --\n",
              "│    │    └─Sequential: 3-19             [1, 256, 56, 56]          [1, 256, 28, 28]          590,592\n",
              "├─ConvBlock: 1-7                         [1, 256, 28, 28]          [1, 512, 28, 28]          --\n",
              "│    └─Sequential: 2-8                   [1, 256, 28, 28]          [1, 512, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-20                 [1, 256, 28, 28]          [1, 512, 28, 28]          1,180,160\n",
              "│    │    └─BatchNorm2d: 3-21            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024\n",
              "│    │    └─ReLU: 3-22                   [1, 512, 28, 28]          [1, 512, 28, 28]          --\n",
              "├─Sequential: 1-8                        [1, 512, 28, 28]          [1, 512, 14, 14]          --\n",
              "│    └─ConvBlock: 2-9                    [1, 512, 28, 28]          [1, 512, 28, 28]          --\n",
              "│    │    └─Sequential: 3-23             [1, 512, 28, 28]          [1, 512, 28, 28]          2,360,832\n",
              "│    └─ConvBlock: 2-10                   [1, 512, 28, 28]          [1, 512, 14, 14]          --\n",
              "│    │    └─Sequential: 3-24             [1, 512, 28, 28]          [1, 512, 14, 14]          2,360,832\n",
              "├─ConvBlock: 1-9                         [1, 512, 14, 14]          [1, 512, 14, 14]          --\n",
              "│    └─Sequential: 2-11                  [1, 512, 14, 14]          [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-25                 [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808\n",
              "│    │    └─BatchNorm2d: 3-26            [1, 512, 14, 14]          [1, 512, 14, 14]          1,024\n",
              "│    │    └─ReLU: 3-27                   [1, 512, 14, 14]          [1, 512, 14, 14]          --\n",
              "├─Sequential: 1-10                       [1, 512, 14, 14]          [1, 512, 7, 7]            --\n",
              "│    └─ConvBlock: 2-12                   [1, 512, 14, 14]          [1, 512, 14, 14]          --\n",
              "│    │    └─Sequential: 3-28             [1, 512, 14, 14]          [1, 512, 14, 14]          2,360,832\n",
              "│    └─ConvBlock: 2-13                   [1, 512, 14, 14]          [1, 512, 7, 7]            --\n",
              "│    │    └─Sequential: 3-29             [1, 512, 14, 14]          [1, 512, 7, 7]            2,360,832\n",
              "├─AdaptiveAvgPool2d: 1-11                [1, 512, 7, 7]            [1, 512, 7, 7]            --\n",
              "├─Sequential: 1-12                       [1, 25088]                [1, 10]                   --\n",
              "│    └─Linear: 2-14                      [1, 25088]                [1, 4096]                 102,764,544\n",
              "│    └─ReLU: 2-15                        [1, 4096]                 [1, 4096]                 --\n",
              "│    └─Dropout: 2-16                     [1, 4096]                 [1, 4096]                 --\n",
              "│    └─Linear: 2-17                      [1, 4096]                 [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-18                        [1, 4096]                 [1, 4096]                 --\n",
              "│    └─Dropout: 2-19                     [1, 4096]                 [1, 4096]                 --\n",
              "│    └─Linear: 2-20                      [1, 4096]                 [1, 10]                   40,970\n",
              "===================================================================================================================\n",
              "Total params: 134,309,962\n",
              "Trainable params: 134,309,962\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 15.48\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 216.83\n",
              "Params size (MB): 537.24\n",
              "Estimated Total Size (MB): 754.67\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "FHetTSmlgSbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋은 원래 논문에서 ILSVRC 데이터를 사용하지만 교육용이기에 resnet에서 사용했던 CIFAR10을 사용하기로 함"
      ],
      "metadata": {
        "id": "jRu26yA2CCUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "xAlpbnhjFYNu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/CIFAR10'\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)"
      ],
      "metadata": {
        "id": "n2vac3vfFZHm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "file_path = '/content/drive/MyDrive/resnet/mean_std.json'\n",
        "\n",
        "# JSON 파일에서 데이터 불러오기\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "mean = data['mean']\n",
        "std = data['std']\n",
        "mean,std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3l1X8EFC2uU",
        "outputId": "30b11e99-83e5-4373-ea1e-45f26987afe3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.491399884223938, 0.48215845227241516, 0.4465309679508209],\n",
              " [0.2023009955883026, 0.19941280782222748, 0.20096160471439362])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 전처리\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기 변경\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),  # 계산된 평균과 표준편차를 이용한 정규화\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기 변경\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),  # 계산된 평균과 표준편차를 이용한 정규화\n",
        "])\n",
        "\n",
        "\n",
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root=path, train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "jLBvoGOIFl1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fcace3-959b-40e4-b56e-eb619386bd4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 정보를 출력하는 함수\n",
        "def print_dataloader_info(dataloader, loader_name):\n",
        "    print(f\"{loader_name} 정보:\")\n",
        "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "        print(f\"배치 인덱스: {batch_idx}\")\n",
        "        print(f\"이미지 크기: {images.size()}\")\n",
        "        if isinstance(labels, torch.Tensor):\n",
        "            print(f\"라벨 크기: {labels.size()}\")\n",
        "            print(f'라벨의 데이터타입 : {labels[0].dtype}')\n",
        "        else:\n",
        "            print(f\"라벨 크기: {len(labels)}\")\n",
        "            print(f'라벨의 데이터타입 : {type(labels[0])}')\n",
        "        if batch_idx == 0:  # 첫 번째 배치 정보만 출력\n",
        "            break\n",
        "\n",
        "# train_loader 정보 출력\n",
        "print_dataloader_info(trainloader, \"Train Loader\")\n",
        "print(\"\\n\")\n",
        "# test_loader 정보 출력\n",
        "print_dataloader_info(testloader, \"Test Loader\")"
      ],
      "metadata": {
        "id": "TOU9EYmTFn0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b197a4-191b-4a77-b7db-f2bef012c998"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader 정보:\n",
            "배치 인덱스: 0\n",
            "이미지 크기: torch.Size([4, 3, 224, 224])\n",
            "라벨 크기: torch.Size([4])\n",
            "라벨의 데이터타입 : torch.int64\n",
            "\n",
            "\n",
            "Test Loader 정보:\n",
            "배치 인덱스: 0\n",
            "이미지 크기: torch.Size([4, 3, 224, 224])\n",
            "라벨 크기: torch.Size([4])\n",
            "라벨의 데이터타입 : torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img,label = next(iter(trainloader))\n",
        "img[0],label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09CKE3-2JaGp",
        "outputId": "427f6aa6-4017-4c31-ea8a-1284567e2ba7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.4324, -0.4324, -0.4324,  ...,  1.0602,  1.0602,  1.0602],\n",
              "          [-0.4324, -0.4324, -0.4324,  ...,  1.0602,  1.0602,  1.0602],\n",
              "          [-0.4324, -0.4324, -0.4324,  ...,  1.0602,  1.0602,  1.0602],\n",
              "          ...,\n",
              "          [-0.9558, -0.9558, -0.9558,  ..., -1.5567, -1.5567, -1.5567],\n",
              "          [-0.9558, -0.9558, -0.9558,  ..., -1.5567, -1.5567, -1.5567],\n",
              "          [-0.9558, -0.9558, -0.9558,  ..., -1.5567, -1.5567, -1.5567]],\n",
              " \n",
              "         [[-0.7660, -0.7660, -0.7660,  ...,  1.5742,  1.5742,  1.5742],\n",
              "          [-0.7660, -0.7660, -0.7660,  ...,  1.5742,  1.5742,  1.5742],\n",
              "          [-0.7660, -0.7660, -0.7660,  ...,  1.5742,  1.5742,  1.5742],\n",
              "          ...,\n",
              "          [-1.1986, -1.1986, -1.1986,  ..., -1.7689, -1.7689, -1.7689],\n",
              "          [-1.1986, -1.1986, -1.1986,  ..., -1.7689, -1.7689, -1.7689],\n",
              "          [-1.1986, -1.1986, -1.1986,  ..., -1.7689, -1.7689, -1.7689]],\n",
              " \n",
              "         [[-1.2853, -1.2853, -1.2853,  ...,  2.5785,  2.5785,  2.5785],\n",
              "          [-1.2853, -1.2853, -1.2853,  ...,  2.5785,  2.5785,  2.5785],\n",
              "          [-1.2853, -1.2853, -1.2853,  ...,  2.5785,  2.5785,  2.5785],\n",
              "          ...,\n",
              "          [-1.2463, -1.2463, -1.2463,  ..., -1.7341, -1.7341, -1.7341],\n",
              "          [-1.2463, -1.2463, -1.2463,  ..., -1.7341, -1.7341, -1.7341],\n",
              "          [-1.2463, -1.2463, -1.2463,  ..., -1.7341, -1.7341, -1.7341]]]),\n",
              " tensor(9))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련\n"
      ],
      "metadata": {
        "id": "k24XbiMpgTMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "num_epochs = 10\n",
        "epoch_step = 2\n",
        "\n",
        "# Loss function, optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "X-Y8F_dtEQtR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(model, data_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    global epoch_step\n",
        "    running_size, running_loss, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "        pbar = tqdm(data_loader)\n",
        "    else:\n",
        "        pbar = data_loader\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images,  labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_size += images.size(0)\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "            pbar.set_description('[Training] loss: ' +\n",
        "                                f'{running_loss / running_size:.4f}, accuracy: ' +\n",
        "                                f'{correct / running_size:.4f}')\n",
        "        del images, labels, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_accuracy = correct / running_size\n",
        "    avg_loss = running_loss / running_size\n",
        "\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "def model_eval(model, data_loader, criterion, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss, correct = 0.0, 0.0\n",
        "\n",
        "        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "            pbar = tqdm(data_loader)\n",
        "        else:\n",
        "            pbar = data_loader\n",
        "\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += torch.sum(pred == labels).item()\n",
        "            running_loss += criterion(outputs, labels).item() * images.size(0)\n",
        "\n",
        "        accuracy = correct / len(data_loader.dataset)\n",
        "        loss = running_loss / len(data_loader.dataset)\n",
        "        return loss, accuracy"
      ],
      "metadata": {
        "id": "OZnUAuffEIqT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/vgg'\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "metadata": {
        "id": "64VACM-2_6jj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 평가 코드\n",
        "loss, accuracy = [], []\n",
        "num_epochs = 10\n",
        "epoch_step = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = model_train(model, trainloader, criterion, optimizer, epoch)\n",
        "    test_loss, test_accuracy = model_eval(model, testloader, criterion, epoch)\n",
        "\n",
        "    loss.append([train_loss, test_loss])\n",
        "    accuracy.append([train_accuracy, test_accuracy])\n",
        "\n",
        "    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n",
        "        print(f\"epoch {epoch+1:03d}, Training loss: \" +\n",
        "              f\"{train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
        "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    model_save_path = os.path.join(directory, 'model.pth')\n",
        "\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc3gWpyOGLHC",
        "outputId": "772c43d5-7c8f-473d-e4ae-e51cdc288406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training] loss: 21.8294, accuracy: 0.1050:   0%|          | 50/12500 [07:44<33:19:24,  9.64s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 확인"
      ],
      "metadata": {
        "id": "j9JpfWZ1gWBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 손실 그래프\n",
        "train_losses, val_losses = zip(*loss)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(val_losses, label='val')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Train-Val Loss')\n",
        "\n",
        "# 정확도 그래프\n",
        "train_accuracies, val_accuracies = zip(*accuracy)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='train')\n",
        "plt.plot(val_accuracies, label='val')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Train-Val Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JMruCfMCHoDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 실행\n"
      ],
      "metadata": {
        "id": "XzkBILYRgYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/vgg/model.pth'\n",
        "model = VGG('vgg16',num_classes=10).to(device)\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "I0FKoaAKH_GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(testloader))\n",
        "images[0]"
      ],
      "metadata": {
        "id": "Q7PB9LwfMh-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].size()"
      ],
      "metadata": {
        "id": "sDIwY_Bk9OtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 텐서를 넘파이 배열로 변환\n",
        "label_indices = labels.numpy()\n",
        "\n",
        "# 각 레이블 인덱스를 클래스 이름으로 변환\n",
        "label_names = [class_labels[idx] for idx in label_indices]\n",
        "\n",
        "print(label_names)"
      ],
      "metadata": {
        "id": "5WOWrHSo9z46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 시각화\n",
        "plt.imshow(images[0])\n",
        "plt.axis('off')  # 축 숨기기\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QmirSF5L9MFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = trainset.classes\n",
        "class_labels"
      ],
      "metadata": {
        "id": "GNeZWY4yOlfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = images[0].unsqueeze(0)\n",
        "test_image.size()"
      ],
      "metadata": {
        "id": "FjfFTXqdM0dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 모델에 통과시켜 예측 수행\n",
        "with torch.no_grad():  # 평가 시에는 gradient를 계산할 필요가 없음\n",
        "    outputs = model(test_image)\n",
        "value, label_idx = torch.max(outputs, 1)\n",
        "value, label_idx"
      ],
      "metadata": {
        "id": "fIMP1_iBILdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 클래스의 인덱스\n",
        "predicted_index = label_idx.item()  # 텐서에서 값을 꺼내 정수로 변환\n",
        "\n",
        "# 인덱스를 클래스 이름으로 매핑\n",
        "predicted_label = class_labels[predicted_index]\n",
        "predicted_label"
      ],
      "metadata": {
        "id": "_LZuC3HMOtrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}